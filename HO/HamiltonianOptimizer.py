# -*- coding: utf-8 -*-
"""Matrix optimizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/148WHjb8r1-dxlGg1pTIE8e5DnrzJKFo1
"""

import numpy as np
import matplotlib.pyplot as plt

class ArrayOptimizer:

  def __init__(self):
    pass

  def InitialArray(self, N, Hermitian = True, Low = -1, High = 1):
    arr = np.random.uniform(low = Low, high = High, size=(N,N)) + 1j*np.zeros((N,N))
    arr = (arr + np.conjugate(arr.T))/2
    if Hermitian == False:
      arr = np.random.uniform(low = Low, high = High, size=(N,N)) + 1j*np.zeros((N,N))
    return arr

  def ErrorGrad(self, arr, eigenvalues):
    n = arr.shape[0]
    val_pred,vec_pred = np.linalg.eigh(arr)
    error = (1/n)*np.sum(((val_pred - eigenvalues)**2))
    DE = np.diag((1/n)*(val_pred - eigenvalues))
    grad = np.dot(vec_pred,np.dot(DE,np.conjugate(vec_pred.T)))
    return error,grad

  def Arrayfit(self, arr, eigenvalues, alpha = 0.1, iter = 10000, tol = 1e-5):
    error_fin, grad_fin = self.ErrorGrad(arr,eigenvalues)
    error_init = np.inf
    grad_init = np.inf
    error_diff = abs(error_fin - error_init)
    for i in range(iter):
      if error_diff > tol:
        arr = arr - alpha*grad_fin
        error_init  = error_fin
        grad_init = grad_fin
        error_fin, grad_fin = self.ErrorGrad(arr,eigenvalues)
        error_diff = abs(error_fin - error_init)
        if error_fin > error_init:
          alpha = alpha/2
      else:
        break
    if error_diff <= tol:
      print(f"Convergence achieved. Final error = {error_fin}, learning rate = {alpha}")
    else:
      print(f"Convergence not achieved. Final error = {error_fin}, learning rate = {alpha}")
    return arr



class HamiltonianOptimizer(ArrayOptimizer):

  def __init__(self):
    """pos_vec: only the nearest neighbor vectors for the unit cell in 3D (each row represents single vector).
       k_vec: k-space vectors in 3D (each row represents single vector)."""
    pass

  def Converter(self, r_vec, k_vec): # For 1D systems when the nearest neighbor position vector and the k-vectors are 1 dimensional.
    if r_vec.ndim != 1 and k_vec.ndim != 1:  # The function converts 1d arrays into a 2d array with 1st column as the non trivial entries.
      raise ValueError("Input arrays should be of dim 1.")
    else:
      r0 = np.zeros((len(r_vec),3))
      r0[:,0] = r_vec
      k0 = np.zeros((len(k_vec),3))
      k0[:,0] = k_vec
    return r0,k0

  def HamiltonianInitializer(self, pos_vec, N_basis): # Creates a 3D array of random real space Hamiltonians with shape equal to number of basis.
    Nr = np.shape(pos_vec)[0]
    arr = np.array([self.InitialArray(N_basis, Hermitian = True) if i == 0 else self.InitialArray(N_basis, Hermitian = False) for i in range(Nr+1)])
    return arr

  def BlochTransform(self, arr, pos_vec, k): # For each k vector, creates a Bloch Hamiltonian.
    Nr = np.shape(pos_vec)[0]
    h = arr[0,:,:].astype(np.complex64)
    for i in range(1,Nr+1):
      add = np.exp(1j*np.dot(k,pos_vec[i-1,:]))*arr[i,:,:]
      h += add + np.conjugate(add.T)
    return h

  def MSEGradient(self, arr, pos_vec, k_vec, N_basis, DFT_eigenvals):
    Nk = np.shape(k_vec)[0]
    h = np.array([self.BlochTransform(arr, pos_vec, k_vec[i,:]) for i in range(Nk)])
    energy_k, eigen_vec = np.linalg.eigh(h)
    diff = (energy_k - DFT_eigenvals)
    MSE = (1/(Nk*N_basis))*np.sum(diff**2)
    R_vec = np.vstack((np.array([0,0,0]),pos_vec))
    nr = np.shape(R_vec)[0]
    exponent = np.exp(-1j*np.dot(R_vec,k_vec.T))
    grad_intermediate = np.einsum("ijk,ikm->ijm",eigen_vec,np.einsum("ijk,ikm->ijm",np.array([np.diag(diff[i,:]) for i in range(Nk)]),np.conjugate(np.transpose(eigen_vec, axes=(0,2,1)))))
    Gradient = (1/(Nk*N_basis))*np.einsum("ij,jkm->ikm",exponent,grad_intermediate)
    return MSE,Gradient

  def HamiltonianFit(self, arr, pos_vec, k_vec, DFT_eigenvals, N_basis, alpha = 0.9, iter = 10000, tol = 1e-2):
    MSE_fin, Gradient_fin = self.MSEGradient(arr, pos_vec, k_vec, N_basis, DFT_eigenvals)
    MSE_init = np.inf
    # MSE_diff = abs(MSE_fin - MSE_init)
    try:
      for i in range(iter):
        if MSE_fin > tol:
          arr = arr - alpha*Gradient_fin
          MSE_init  = MSE_fin
          MSE_fin, Gradient_fin = self.MSEGradient(arr, pos_vec, k_vec, N_basis, DFT_eigenvals)
          # MSE_diff = abs(MSE_fin - MSE_init)
          print(f"Iteration {i+1}, Error = {MSE_fin}, LR = {alpha}") if i%1000 == 0 else None
          if MSE_fin > MSE_init:
            alpha = alpha/2
        else:
          break
    except KeyboardInterrupt:
      print(f"Program stopped by the user at iteration = {i+1}. Returning the array.")
    if MSE_fin <= tol:
      print(f"Convergence achieved. Final error = {MSE_fin}, learning rate = {alpha}")
    else:
      print(f"Convergence not achieved. Final error = {MSE_fin}, learning rate = {alpha}")
    return arr

k_vec = np.load("kpoints.npy")
eigenvalues = np.load("bands_ab.npy")
k_vec = 2*np.pi*k_vec
pos_vec = np.array([[1,0,0],[0,1,0]])
eigenvalues.shape

# Define the High Symmetry path
high_sym = [np.linalg.norm(k_vec[0])]
for i in range(len(k_vec)-1):
	high_sym.append(high_sym[i] + np.linalg.norm(k_vec[i+1]-k_vec[i]))
high_sym = np.array(high_sym)
for i in range(np.shape(eigenvalues)[1]):
  plt.plot(high_sym, eigenvalues[:,i], color = "b")
plt.show()

optimizer = HamiltonianOptimizer()

arr = optimizer.HamiltonianInitializer(pos_vec,32)

arr = optimizer.HamiltonianFit(arr, pos_vec, k_vec, eigenvalues, 32, tol = 1e-3, iter = 50000, alpha = 2)

h = np.array([optimizer.BlochTransform(arr, pos_vec, k_vec[i,:]) for i in range(300)])

vals = np.linalg.eigvalsh(h)

for i in range(32):
  plt.plot(high_sym, vals[:,i], color = "black")
  plt.plot(high_sym, eigenvalues[:,i], color = "blue")
plt.show()